"""
Intent Classifier Module
Ph√¢n lo·∫°i c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng th√†nh c√°c intent
Version 5.7.2 - Fixed CHENG staff KPI routing
"""
import re
from datetime import datetime, timedelta
from typing import Dict, Any, Optional

# ============ INTENT TYPES ============
INTENT_KOC_REPORT = "KOC_REPORT"  # B√°o c√°o KOC Kalle (m·∫∑c ƒë·ªãnh)
INTENT_CHENG_REPORT = "CHENG_REPORT"  # B√°o c√°o KOC Cheng
INTENT_CONTENT_CALENDAR = "CONTENT_CALENDAR_SUMMARY"
INTENT_TASK_SUMMARY = "TASK_SUMMARY"  # Ph√¢n t√≠ch task theo v·ªã tr√≠
INTENT_GENERAL_SUMMARY = "GENERAL_SUMMARY"
INTENT_GPT_CHAT = "GPT_CHAT"  # H·ªèi ChatGPT tr·ª±c ti·∫øp
INTENT_DASHBOARD = "DASHBOARD"  # Dashboard t·ªïng h·ª£p
INTENT_UNKNOWN = "UNKNOWN"

# Keywords ƒë·ªÉ nh·∫≠n d·∫°ng brand Cheng
CHENG_KEYWORDS = ["cheng", "chenglovehair", "cheng love hair"]

# ============ KEYWORDS ============
KOC_KEYWORDS = [
    "koc", "booking", "air", "g·∫Øn gi·ªè", "gan gio", "pr", 
    "ƒë√£ air", "ch∆∞a air", "link air", "th√°ng deal", "tu·∫ßn deal",
    "chi ph√≠", "chi phi", "s·∫£n ph·∫©m", "san pham"
]

CONTENT_KEYWORDS = [
    "content", "l·ªãch", "lich", "c√¥ng vi·ªác", "cong viec",
    "b√†i ƒëƒÉng", "tiktok", "design", "digital"
]

TASK_KEYWORDS = [
    "task", "deadline", "qu√° h·∫°n", "qua han", "overdue", "tr·ªÖ h·∫°n", "tre han",
    "v·ªã tr√≠", "vi tri", "hr", "ecommerce", "content creator",
    "s·∫Øp deadline", "sap deadline", "c√¥ng vi·ªác", "ph√¢n t√≠ch task"
]

# Keywords ƒë·ªÉ g·ªçi GPT tr·ª±c ti·∫øp
GPT_KEYWORDS = [
    "gpt", "chatgpt", "h·ªèi gpt", "hoi gpt", "ask gpt",
    "ai:", "gpt:", "h·ªèi ai", "hoi ai"
]

# T√™n c√°c ph√¢n lo·∫°i s·∫£n ph·∫©m c·ª• th·ªÉ (brands)
BRAND_KEYWORDS = [
    "dark beauty", "lady killer", "ladykiller", "venus", 
    "kalle", "dark", "lady", "killer"
]

# Keywords ƒë·ªÉ filter theo lo·∫°i s·∫£n ph·∫©m
PRODUCT_FILTER_KEYWORDS = {
    "box_qua": ["box qu√†", "set qu√†", "box qua", "set qua", "qu√† t·∫∑ng", "qua tang", "gift box", "giftbox"],
    "nuoc_hoa": ["n∆∞·ªõc hoa", "nuoc hoa", "perfume"],
    "sua_tam": ["s·ªØa t·∫Øm", "sua tam", "body wash"],
}

# Keywords cho Dashboard
DASHBOARD_KEYWORDS = [
    "dashboard", "kpi", "top koc", "doanh s·ªë", "doanh so",
    "li√™n h·ªá", "lien he", "t·ª∑ l·ªá deal", "ty le deal",
    "nh√¢n s·ª±", "nhan su", "hi·ªáu su·∫•t", "hieu suat",
    "gmv", "performance",
    # Trigger m·ªõi
    "c·∫≠p nh·∫≠t t√¨nh h√¨nh", "cap nhat tinh hinh",
    "t√¨nh h√¨nh booking", "tinh hinh booking",
    "c·∫≠p nh·∫≠t booking", "cap nhat booking"
]

# ============ NH√ÇN S·ª∞ MAPPING ============
# Danh s√°ch nh√¢n s·ª± CHENG (ƒë·ªÉ detect v√† route sang CHENG_REPORT)
# Updated v5.7.3 - Danh s√°ch ƒë·∫ßy ƒë·ªß t·ª´ b·∫£ng CHENG Dashboard
CHENG_NHAN_SU_MAPPING = {
    # T√™n ƒë∆°n - s·∫Ω ƒë∆∞·ª£c match th√™m trong report_generator
    "ph∆∞∆°ng": "Ph∆∞∆°ng",  # Could be Ph∆∞∆°ng Anh or Nguy√™n Ph∆∞∆°ng
    "phuong": "Ph∆∞∆°ng",
    # Ph∆∞∆°ng Anh (specific)
    "ph∆∞∆°ng anh": "Ph∆∞∆°ng Anh",
    "phuong anh": "Ph∆∞∆°ng Anh",
    # Nguy√™n Ph∆∞∆°ng (specific)
    "nguy√™n ph∆∞∆°ng": "Nguy√™n Ph∆∞∆°ng",
    "nguyen phuong": "Nguy√™n Ph∆∞∆°ng",
    "nguy√™n": "Nguy√™n Ph∆∞∆°ng",
    "nguyen": "Nguy√™n Ph∆∞∆°ng",
    # Tr√† Mi CHENG
    "tr√† mi cheng": "Tr√† Mi",
    # Qu·ª≥nh Anh
    "qu·ª≥nh anh": "Qu·ª≥nh Anh",
    "quynh anh": "Qu·ª≥nh Anh",
    "qu·ª≥nh": "Qu·ª≥nh Anh",
    "quynh": "Qu·ª≥nh Anh",
    # Thanh Nh√†n
    "thanh nh√†n": "Thanh Nh√†n",
    "thanh nhan": "Thanh Nh√†n",
    "nh√†n": "Thanh Nh√†n",
    "nhan": "Thanh Nh√†n",
    # Thanh Ng√¢n  
    "thanh ng√¢n": "Thanh Ng√¢n",
    "thanh ngan": "Thanh Ng√¢n",
    "ng√¢n": "Thanh Ng√¢n",
    "ngan": "Thanh Ng√¢n",
    # H·∫°nh Di·ªáu
    "h·∫°nh di·ªáu": "Ng√¥ H·∫°nh Di·ªáu",
    "hanh dieu": "Ng√¥ H·∫°nh Di·ªáu",
    "di·ªáu": "Ng√¥ H·∫°nh Di·ªáu",
    "dieu": "Ng√¥ H·∫°nh Di·ªáu",
    # Tr√† Giang
    "tr√† giang": "Tr√† Giang",
    "tra giang": "Tr√† Giang",
    "giang": "Tr√† Giang",
    # H·∫£i Anh
    "h·∫£i anh": "H·∫£i Anh",
    "hai anh": "H·∫£i Anh",
}

# Danh s√°ch nh√¢n s·ª± booking KALLE (ƒë·ªÉ detect t√™n c·ª• th·ªÉ)
NHAN_SU_MAPPING = {
    # T√™n th∆∞·ªùng g·ªçi -> T√™n ƒë·∫ßy ƒë·ªß trong Lark
    "tr√† mi": "Tr√† Mi - Intern Booking",
    "tra mi": "Tr√† Mi - Intern Booking",
    "mi": "Tr√† Mi - Intern Booking",
    "mai": "Nh∆∞ Mai",
    "nh∆∞ mai": "Nh∆∞ Mai",
    "nhu mai": "Nh∆∞ Mai",
    "th·∫£o": "Ph∆∞∆°ng Th·∫£o - Intern Booking",
    "thao": "Ph∆∞∆°ng Th·∫£o - Intern Booking",
    "ph∆∞∆°ng th·∫£o": "Ph∆∞∆°ng Th·∫£o - Intern Booking",
    "d∆∞∆°ng": "L√™ Thu·ª≥ D∆∞∆°ng",
    "duong": "L√™ Thu·ª≥ D∆∞∆°ng",
    "thu·ª≥ d∆∞∆°ng": "L√™ Thu·ª≥ D∆∞∆°ng",
    "thuy duong": "L√™ Thu·ª≥ D∆∞∆°ng",
    "v·ªãt": "L√™ Thu·ª≥ D∆∞∆°ng",
    "vit": "L√™ Thu·ª≥ D∆∞∆°ng",
    "ng·ªçc linh": "Ng·ªçc Linh - Booking Re...",
    "ngoc linh": "Ng·ªçc Linh - Booking Re...",
    "qu√¢n": "Qu√¢n",
    "quan": "Qu√¢n",
    "ch√¢u": "B·∫£o Ch√¢u - Booking Remote",
    "chau": "B·∫£o Ch√¢u - Booking Remote",
    "b·∫£o ch√¢u": "B·∫£o Ch√¢u - Booking Remote",
    "bao chau": "B·∫£o Ch√¢u - Booking Remote",
}

# V·ªã tr√≠ c·ª• th·ªÉ
VI_TRI_MAPPING = {
    "hr": ["hr", "nh√¢n s·ª±", "nhan su"],
    "content creator tiktok": ["content creator", "content tiktok", "creator tiktok"],
    "ecommerce": ["ecommerce", "e-commerce", "tmdt", "th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠"],
    "design": ["design", "thi·∫øt k·∫ø", "thiet ke"],
    "pr": ["pr", "pr booking"],
}

# ============ TIME PARSING ============
def parse_month(text: str) -> Optional[int]:
    """Extract th√°ng t·ª´ text"""
    text = text.lower()
    
    # Pattern: th√°ng 12, th√°ng 1, t12, t1
    patterns = [
        r'th√°ng\s*(\d{1,2})',
        r'thang\s*(\d{1,2})',
        r't(\d{1,2})\b',
        r'(\d{1,2})/\d{4}',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            month = int(match.group(1))
            if 1 <= month <= 12:
                return month
    
    # Th√°ng hi·ªán t·∫°i n·∫øu kh√¥ng t√¨m th·∫•y
    return None

def parse_week(text: str) -> Optional[int]:
    """Extract tu·∫ßn t·ª´ text"""
    text = text.lower()
    
    # Pattern: tu·∫ßn 1, tu·∫ßn 2, tu·∫ßn n√†y
    patterns = [
        r'tu·∫ßn\s*(\d)',
        r'tuan\s*(\d)',
        r'week\s*(\d)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            week = int(match.group(1))
            if 1 <= week <= 5:
                return week
    
    # "tu·∫ßn n√†y" -> t√≠nh tu·∫ßn hi·ªán t·∫°i trong th√°ng
    if "tu·∫ßn n√†y" in text or "tuan nay" in text or "this week" in text:
        today = datetime.now()
        week_of_month = (today.day - 1) // 7 + 1
        return min(week_of_month, 4)
    
    return None

def parse_team(text: str) -> Optional[str]:
    """Extract team t·ª´ text"""
    text = text.lower()
    
    teams = {
        "content": ["content", "content social", "content tiktok"],
        "design": ["design", "thi·∫øt k·∫ø"],
        "digital": ["digital", "ads"],
        "tiktok": ["tiktok", "tik tok"],
        "tmdt": ["tmdt", "th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠", "e-commerce"],
        "pr": ["pr", "booking", "pr booking"],
    }
    
    for team_name, keywords in teams.items():
        for kw in keywords:
            if kw in text:
                return team_name
    
    return None

def parse_vi_tri(text: str) -> Optional[str]:
    """Extract v·ªã tr√≠ t·ª´ text"""
    text = text.lower()
    
    for vi_tri, keywords in VI_TRI_MAPPING.items():
        for kw in keywords:
            if kw in text:
                return vi_tri
    
    return None

def get_current_week_range() -> tuple:
    """L·∫•y ng√†y ƒë·∫ßu v√† cu·ªëi c·ªßa tu·∫ßn hi·ªán t·∫°i"""
    today = datetime.now()
    start_of_week = today - timedelta(days=today.weekday())  # Monday
    end_of_week = start_of_week + timedelta(days=6)  # Sunday
    
    return (
        start_of_week.strftime("%Y-%m-%d"),
        end_of_week.strftime("%Y-%m-%d")
    )

# ============ CLASSIFIER ============
def extract_gpt_question(text: str) -> str:
    """
    Tr√≠ch xu·∫•t c√¢u h·ªèi cho GPT t·ª´ text.
    Lo·∫°i b·ªè prefix nh∆∞ "gpt:", "h·ªèi gpt", etc.
    """
    text_lower = text.lower()
    
    # C√°c pattern c·∫ßn lo·∫°i b·ªè
    prefixes = [
        r'^gpt[:\s]+',
        r'^chatgpt[:\s]+',
        r'^h·ªèi gpt[:\s]+',
        r'^hoi gpt[:\s]+',
        r'^ask gpt[:\s]+',
        r'^ai[:\s]+',
        r'^h·ªèi ai[:\s]+',
        r'^hoi ai[:\s]+',
    ]
    
    result = text
    for prefix in prefixes:
        result = re.sub(prefix, '', result, flags=re.IGNORECASE)
    
    return result.strip()


def classify_intent(text: str) -> Dict[str, Any]:
    """
    Ph√¢n lo·∫°i intent t·ª´ c√¢u h·ªèi
    
    Args:
        text: C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
    
    Returns:
        Dict ch·ª©a intent v√† c√°c parameters
    """
    text_lower = text.lower()
    
    # ========== CHECK GPT CHAT FIRST ==========
    # ∆Øu ti√™n cao nh·∫•t: N·∫øu user mu·ªën h·ªèi GPT tr·ª±c ti·∫øp
    # Patterns: "gpt:", "gpt vi·∫øt", "gpt h·ªèi", "chatgpt", etc.
    gpt_triggers = [
        "gpt:", "gpt ", "chatgpt:", "chatgpt ", 
        "h·ªèi gpt", "hoi gpt", "ask gpt",
        "ai:", "h·ªèi ai", "hoi ai"
    ]
    is_gpt_chat = any(trigger in text_lower for trigger in gpt_triggers)
    
    # Nh∆∞ng KH√îNG ph·∫£i GPT chat n·∫øu c√≥ t·ª´ kh√≥a KOC/booking/task ƒëi k√®m
    # V√≠ d·ª•: "GPT vi·∫øt brief cho KOC" ‚Üí v·∫´n l√† GPT chat
    # Nh∆∞ng: "T·ªïng h·ª£p KOC th√°ng 12" ‚Üí KH√îNG ph·∫£i GPT chat
    has_report_keywords = any(kw in text_lower for kw in ["t·ªïng h·ª£p", "tong hop", "b√°o c√°o", "bao cao", "th·ªëng k√™", "thong ke", "t√≥m t·∫Øt", "tom tat"])
    
    if is_gpt_chat and not has_report_keywords:
        question = extract_gpt_question(text)
        return {
            "intent": INTENT_GPT_CHAT,
            "question": question,
            "original_text": text
        }
    
    # Count keywords
    koc_score = sum(1 for kw in KOC_KEYWORDS if kw in text_lower)
    content_score = sum(1 for kw in CONTENT_KEYWORDS if kw in text_lower)
    task_score = sum(1 for kw in TASK_KEYWORDS if kw in text_lower)
    
    # Check for GENERAL summary - ch·ªâ khi h·ªèi v·ªÅ "k·∫øt qu·∫£ c√¥ng vi·ªác", "t·ªïng h·ª£p tu·∫ßn/th√°ng" m√† KH√îNG c√≥ KOC/task c·ª• th·ªÉ
    general_keywords = ["t·ªïng h·ª£p k·∫øt qu·∫£", "t·ªïng h·ª£p c√¥ng vi·ªác", "b√°o c√°o tu·∫ßn", "b√°o c√°o th√°ng", "overview tu·∫ßn", "summary tu·∫ßn"]
    is_general = any(kw in text_lower for kw in general_keywords)
    
    # N·∫øu c√≥ "t·ªïng h·ª£p" NH∆ØNG ƒëi k√®m KOC -> v·∫´n l√† KOC report
    # V√≠ d·ª•: "t·ªïng h·ª£p chi ph√≠ KOC" -> KOC_REPORT, kh√¥ng ph·∫£i GENERAL
    has_tong_hop = "t·ªïng h·ª£p" in text_lower or "tong hop" in text_lower
    
    # Check for task analysis specifically
    is_task_analysis = any(kw in text_lower for kw in [
        "qu√° h·∫°n", "qua han", "overdue", "tr·ªÖ h·∫°n", "deadline",
        "ph√¢n t√≠ch task", "v·ªã tr√≠", "vi tri"
    ])
    
    # Check if asking about specific brand (Dark Beauty, Lady Killer, etc.)
    is_brand_specific = any(brand in text_lower for brand in BRAND_KEYWORDS)
    
    # Parse time info
    month = parse_month(text)
    week = parse_week(text)
    team = parse_team(text)
    vi_tri = parse_vi_tri(text)
    
    # Detect product filter (box qu√†, n∆∞·ªõc hoa, etc.)
    product_filter = None
    for filter_key, keywords in PRODUCT_FILTER_KEYWORDS.items():
        if any(kw in text_lower for kw in keywords):
            product_filter = filter_key
            break
    
    # Default to current month if not specified
    current_month = datetime.now().month
    year = datetime.now().year
    
    # ========== DETERMINE INTENT ==========
    
    # 0. Dashboard - khi h·ªèi v·ªÅ KPI, top KOC, doanh s·ªë, li√™n h·ªá nh√¢n s·ª±
    dashboard_score = sum(1 for kw in DASHBOARD_KEYWORDS if kw in text_lower)
    is_dashboard = dashboard_score >= 1 or any(kw in text_lower for kw in [
        "top koc", "kpi nh√¢n s·ª±", "kpi nhan su", "doanh s·ªë koc", "doanh so koc",
        "t·ª∑ l·ªá li√™n h·ªá", "ty le lien he", "dashboard", "hi·ªáu su·∫•t nh√¢n s·ª±",
        # Trigger m·ªõi
        "c·∫≠p nh·∫≠t t√¨nh h√¨nh", "cap nhat tinh hinh",
        "t√¨nh h√¨nh booking", "tinh hinh booking"
    ])
    
    # === CHECK CHENG TR∆Ø·ªöC - n·∫øu c√≥ keyword "cheng" ===
    is_cheng = any(kw in text_lower for kw in CHENG_KEYWORDS)
    
    if is_cheng:
        # N·∫øu c√≥ "cheng" + (booking/koc/b√°o c√°o/c·∫≠p nh·∫≠t) ‚Üí CHENG_REPORT
        if koc_score > 0 or has_tong_hop or has_report_keywords or is_dashboard:
            return {
                "intent": INTENT_CHENG_REPORT,
                "month": month if month else current_month,
                "week": week,
                "year": year,
                "group_by": "product",
                "product_filter": product_filter,
                "original_text": text
            }
    
    # ========== DETECT NH√ÇN S·ª∞ C·ª§ TH·ªÇ ==========
    # IMPORTANT: Sort by length descending to prioritize longer matches first
    # This prevents "ph∆∞∆°ng" matching when "ph∆∞∆°ng th·∫£o" was intended
    
    # Check KALLE staff FIRST (because has longer specific names like "ph∆∞∆°ng th·∫£o")
    kalle_nhan_su_detected = None
    sorted_kalle_mapping = sorted(NHAN_SU_MAPPING.items(), key=lambda x: len(x[0]), reverse=True)
    for short_name, full_name in sorted_kalle_mapping:
        if short_name in text_lower:
            pattern = r'\b' + re.escape(short_name) + r'\b'
            if re.search(pattern, text_lower):
                kalle_nhan_su_detected = full_name
                is_dashboard = True
                break
    
    # Check CHENG staff (only if no KALLE match found)
    cheng_nhan_su_detected = None
    if not kalle_nhan_su_detected:
        sorted_cheng_mapping = sorted(CHENG_NHAN_SU_MAPPING.items(), key=lambda x: len(x[0]), reverse=True)
        for short_name, full_name in sorted_cheng_mapping:
            if short_name in text_lower:
                pattern = r'\b' + re.escape(short_name) + r'\b'
                if re.search(pattern, text_lower):
                    cheng_nhan_su_detected = full_name
                    break
    
    # N·∫øu detect ƒë∆∞·ª£c nh√¢n s·ª± CHENG ‚Üí route sang CHENG_REPORT v·ªõi nhan_su_filter
    if cheng_nhan_su_detected and is_dashboard:
        return {
            "intent": INTENT_CHENG_REPORT,
            "month": month if month else current_month,
            "week": week,
            "year": year,
            "report_type": "kpi_ca_nhan",
            "nhan_su": cheng_nhan_su_detected,
            "original_text": text
        }
    
    # KALLE staff already checked above - no need to duplicate
    
    if is_dashboard:
        # X√°c ƒë·ªãnh lo·∫°i b√°o c√°o dashboard
        report_type = "full"  # M·∫∑c ƒë·ªãnh: b√°o c√°o ƒë·∫ßy ƒë·ªß
        
        # N·∫øu c√≥ nh√¢n s·ª± c·ª• th·ªÉ -> b√°o c√°o c√° nh√¢n
        if kalle_nhan_su_detected:
            report_type = "kpi_ca_nhan"
        elif "top koc" in text_lower or "doanh s·ªë" in text_lower or "doanh so" in text_lower or "gmv" in text_lower:
            report_type = "top_koc"
        elif "li√™n h·ªá" in text_lower or "lien he" in text_lower or "t·ª∑ l·ªá deal" in text_lower:
            report_type = "lien_he"
        elif "kpi" in text_lower and ("nh√¢n s·ª±" in text_lower or "nhan su" in text_lower):
            report_type = "kpi_nhan_su"
        elif "c·∫£nh b√°o" in text_lower or "canh bao" in text_lower or "warning" in text_lower or "alert" in text_lower:
            report_type = "canh_bao"
        
        return {
            "intent": INTENT_DASHBOARD,
            "month": month if month else current_month,
            "week": week,
            "year": year,
            "report_type": report_type,  # "full", "top_koc", "lien_he", "kpi_nhan_su", "kpi_ca_nhan", "canh_bao"
            "nhan_su": kalle_nhan_su_detected,  # T√™n nh√¢n s·ª± c·ª• th·ªÉ (n·∫øu c√≥)
            "original_text": text
        }
    
    # 2. KOC Report (KALLE - m·∫∑c ƒë·ªãnh) - ∆∞u ti√™n cao nh·∫•t khi c√≥ t·ª´ kh√≥a KOC
    if koc_score > 0 and koc_score >= content_score:
        # Quy·∫øt ƒë·ªãnh group_by:
        # - "brand" n·∫øu h·ªèi c·ª• th·ªÉ Dark Beauty, Lady Killer, etc.
        # - "product" m·∫∑c ƒë·ªãnh (N∆∞·ªõc hoa, Box qu√†)
        group_by = "brand" if is_brand_specific else "product"
        
        return {
            "intent": INTENT_KOC_REPORT,
            "month": month if month else current_month,
            "week": week,
            "year": year,
            "filters": extract_koc_filters(text_lower),
            "group_by": group_by,  # "product" ho·∫∑c "brand"
            "product_filter": product_filter,  # "box_qua", "nuoc_hoa", etc.
            "original_text": text
        }
    
    # 2. Task Summary - khi h·ªèi v·ªÅ deadline, qu√° h·∫°n, v·ªã tr√≠
    if task_score > 0 and is_task_analysis:
        return {
            "intent": INTENT_TASK_SUMMARY,
            "month": month,  # C√≥ th·ªÉ None ƒë·ªÉ l·∫•y t·∫•t c·∫£
            "vi_tri": vi_tri,
            "year": year,
            "original_text": text
        }
    
    # 3. Content Calendar - khi h·ªèi v·ªÅ l·ªãch content
    if content_score > 0 and not is_general:
        start_date, end_date = get_week_range_for_month(month, year) if month else get_current_week_range()
        
        return {
            "intent": INTENT_CONTENT_CALENDAR,
            "range_type": "month" if month else "week",
            "start_date": start_date,
            "end_date": end_date,
            "month": month,
            "team_filter": team,
            "vi_tri_filter": vi_tri,
            "original_text": text
        }
    
    # 4. General Summary - CH·ªà khi h·ªèi t·ªïng h·ª£p chung (kh√¥ng c√≥ KOC/task c·ª• th·ªÉ)
    if is_general:
        return {
            "intent": INTENT_GENERAL_SUMMARY,
            "month": month if month else current_month,
            "week": week,
            "year": year,
            "team": team,
            "original_text": text
        }
    
    # 5. Unknown
    return {
        "intent": INTENT_UNKNOWN,
        "original_text": text,
        "suggestion": "B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ:\n‚Ä¢ B√°o c√°o KOC: \"T√≥m t·∫Øt KOC th√°ng 12\"\n‚Ä¢ L·ªãch content: \"L·ªãch content th√°ng 12\"\n‚Ä¢ Ph√¢n t√≠ch task: \"Task qu√° h·∫°n theo v·ªã tr√≠\"\n‚Ä¢ T·ªïng h·ª£p: \"T·ªïng h·ª£p k·∫øt qu·∫£ c√¥ng vi·ªác th√°ng 12\""
    }


def get_week_range_for_month(month: int, year: int) -> tuple:
    """L·∫•y ng√†y ƒë·∫ßu v√† cu·ªëi c·ªßa th√°ng"""
    start_date = f"{year}-{month:02d}-01"
    
    # Cu·ªëi th√°ng
    if month == 12:
        end_date = f"{year}-12-31"
    else:
        # Ng√†y ƒë·∫ßu th√°ng sau - 1
        from datetime import date
        import calendar
        last_day = calendar.monthrange(year, month)[1]
        end_date = f"{year}-{month:02d}-{last_day:02d}"
    
    return (start_date, end_date)

def extract_koc_filters(text: str) -> list:
    """Extract c√°c filter c·ª• th·ªÉ cho KOC report"""
    filters = []
    
    if "ch∆∞a air" in text or "chua air" in text:
        filters.append("chua_air")
    if "ƒë√£ air" in text or "da air" in text:
        filters.append("da_air")
    if "ch∆∞a c√≥ link" in text or "thi·∫øu link" in text or "ch∆∞a link" in text:
        filters.append("link_missing")
    if "ch∆∞a g·∫Øn gi·ªè" in text or "chua gan gio" in text:
        filters.append("chua_gan_gio")
    if "ƒë√£ g·∫Øn gi·ªè" in text or "da gan gio" in text:
        filters.append("da_gan_gio")
    
    return filters

# ============ TEST ============
def test_classifier():
    """Test intent classifier"""
    test_cases = [
        "T√≥m t·∫Øt KOC th√°ng 12 gi√∫p ch·ªã",
        "KOC tu·∫ßn 2 ai air r·ªìi?",
        "Li·ªát k√™ KOC ch∆∞a g·∫Øn gi·ªè th√°ng 12",
        "ai ƒë√£ air nh∆∞ng ch∆∞a c√≥ link b√†i trong th√°ng 12?",
        "L·ªãch content tu·∫ßn n√†y",
        "C√°c task TikTok tu·∫ßn n√†y c√≥ ƒë·∫ßu n√†o tr·ªÖ kh√¥ng?",
        "Cho ch·ªã list content c√≥ t·ª´ Noel trong th√°ng 12",
        "Summary overview tu·∫ßn n√†y: content + booking",
        "Xin ch√†o Jarvis",
        # Test CHENG staff detection
        "KPI c·ªßa Ph∆∞∆°ng th√°ng 12",
        "KPI c·ªßa Linh",
        "Jarvis KPI c·ªßa Trang",
        # Test KALLE staff detection
        "KPI c·ªßa Mai th√°ng 12",
        "KPI c·ªßa Th·∫£o",
    ]
    
    print("=" * 50)
    print("INTENT CLASSIFIER TEST")
    print("=" * 50)
    
    for text in test_cases:
        result = classify_intent(text)
        print(f"\nüìù Input: {text}")
        print(f"üéØ Intent: {result['intent']}")
        if result.get('nhan_su'):
            print(f"üë§ Nh√¢n s·ª±: {result['nhan_su']}")
        print(f"üìä Params: {result}")

if __name__ == "__main__":
    test_classifier()
