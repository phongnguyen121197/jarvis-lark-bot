"""
TikTok Ads Web Crawler
Crawl spending data t·ª´ TikTok Ads Manager b·∫±ng Playwright
"""
import os
import re
import json
import asyncio
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
from playwright.async_api import async_playwright, Browser, Page, TimeoutError as PlaywrightTimeout

# Config
TIKTOK_ADS_URL = "https://ads.tiktok.com/i18n/account/payment"
PRIMARY_ADVERTISER_ID = os.getenv("TIKTOK_PRIMARY_ADVERTISER_ID", "7089362853240553474")
COOKIES_FILE = "/tmp/tiktok_ads_cookies.json"

# H·∫°n m·ª©c t√≠n d·ª•ng
CREDIT_LIMIT = float(os.getenv("TIKTOK_CREDIT_LIMIT", "163646248"))
WARNING_THRESHOLD = float(os.getenv("TIKTOK_WARNING_THRESHOLD", "85"))

# Cache
_cached_data: Dict[str, Any] = {
    "spending": 0,
    "credit_limit": CREDIT_LIMIT,
    "next_billing_date": None,
    "account_name": None,
    "updated_at": None,
    "cache_ttl": 3600,  # 1 hour
}


def save_cookies(cookies: list):
    """L∆∞u cookies v√†o file"""
    try:
        with open(COOKIES_FILE, 'w') as f:
            json.dump(cookies, f)
        print(f"‚úÖ Saved {len(cookies)} cookies")
    except Exception as e:
        print(f"‚ùå Error saving cookies: {e}")


def load_cookies() -> Optional[list]:
    """Load cookies t·ª´ env ho·∫∑c file"""
    cookies = None
    
    # Try env first (Railway friendly)
    cookies_json = os.getenv("TIKTOK_COOKIES_JSON")
    if cookies_json:
        try:
            cookies = json.loads(cookies_json)
            print(f"‚úÖ Loaded {len(cookies)} cookies from env")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to parse TIKTOK_COOKIES_JSON: {e}")
    
    # Try file fallback
    if not cookies:
        try:
            if os.path.exists(COOKIES_FILE):
                with open(COOKIES_FILE, 'r') as f:
                    cookies = json.load(f)
                    print(f"‚úÖ Loaded {len(cookies)} cookies from file")
        except Exception as e:
            print(f"‚ùå Error loading cookies from file: {e}")
    
    if not cookies:
        print("‚ö†Ô∏è No cookies found (env or file)")
        return None
    
    # Normalize cookies for Playwright
    return normalize_cookies(cookies)


def normalize_cookies(cookies: list) -> list:
    """
    Normalize cookies ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi Playwright
    - Fix sameSite values
    - Remove invalid fields
    """
    normalized = []
    
    for cookie in cookies:
        # Ch·ªâ gi·ªØ c√°c field c·∫ßn thi·∫øt
        clean_cookie = {
            "name": cookie.get("name", ""),
            "value": cookie.get("value", ""),
            "domain": cookie.get("domain", ".tiktok.com"),
            "path": cookie.get("path", "/"),
        }
        
        # Skip cookies without name or value
        if not clean_cookie["name"] or not clean_cookie["value"]:
            continue
        
        # Handle sameSite - Playwright requires: Strict, Lax, or None
        same_site = str(cookie.get("sameSite", "")).lower()
        if same_site == "strict":
            clean_cookie["sameSite"] = "Strict"
        elif same_site == "none":
            clean_cookie["sameSite"] = "None"
        else:
            # Default to Lax for unspecified/invalid/lax
            clean_cookie["sameSite"] = "Lax"
        
        # Handle secure
        if cookie.get("secure"):
            clean_cookie["secure"] = True
        
        # Handle httpOnly
        if cookie.get("httpOnly"):
            clean_cookie["httpOnly"] = True
        
        # Handle expires (Playwright uses expires as seconds since epoch)
        if cookie.get("expirationDate"):
            try:
                clean_cookie["expires"] = float(cookie["expirationDate"])
            except:
                pass
        elif cookie.get("expires") and cookie.get("expires") != -1:
            try:
                clean_cookie["expires"] = float(cookie["expires"])
            except:
                pass
        
        normalized.append(clean_cookie)
    
    print(f"üîß Normalized {len(normalized)} cookies")
    return normalized


def is_cache_valid() -> bool:
    """Ki·ªÉm tra cache c√≤n valid kh√¥ng"""
    if not _cached_data["updated_at"]:
        return False
    
    try:
        updated = datetime.fromisoformat(_cached_data["updated_at"])
        now = datetime.now()
        delta = (now - updated).total_seconds()
        return delta < _cached_data["cache_ttl"]
    except:
        return False


def get_cached_data() -> Dict[str, Any]:
    """L·∫•y data t·ª´ cache"""
    return _cached_data.copy()


async def crawl_spending_data(advertiser_id: str = None) -> Dict[str, Any]:
    """
    Crawl spending data t·ª´ TikTok Ads Manager
    """
    target_id = advertiser_id or PRIMARY_ADVERTISER_ID
    url = f"{TIKTOK_ADS_URL}?aadvid={target_id}"
    
    print(f"üîç Crawling TikTok Ads: {url}")
    
    result = {
        "success": False,
        "spending": 0,
        "credit_limit": CREDIT_LIMIT,
        "next_billing_date": None,
        "account_name": None,
        "error": None,
        "login_required": False
    }
    
    browser = None
    
    try:
        async with async_playwright() as p:
            # Launch browser
            browser = await p.chromium.launch(
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-gpu',
                    '--disable-software-rasterizer',
                    '--disable-extensions',
                    '--single-process',
                    '--disable-blink-features=AutomationControlled'
                ]
            )
            
            context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                locale='en-US'
            )
            
            # Load cookies n·∫øu c√≥
            cookies = load_cookies()
            if cookies:
                await context.add_cookies(cookies)
                print("üç™ Added cookies to context")
            
            page = await context.new_page()
            
            # Set extra headers
            await page.set_extra_http_headers({
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
            })
            
            # Navigate to payment page
            try:
                response = await page.goto(url, wait_until='networkidle', timeout=30000)
                print(f"üìÑ Page loaded: {page.url}")
            except PlaywrightTimeout:
                print("‚è±Ô∏è Timeout waiting for networkidle, continuing...")
            
            # Check if redirected to login
            current_url = page.url
            if 'login' in current_url.lower() or 'signin' in current_url.lower():
                result["error"] = "C·∫ßn ƒëƒÉng nh·∫≠p l·∫°i TikTok Ads Manager"
                result["login_required"] = True
                print("üîê Login required")
                await browser.close()
                return result
            
            # Wait for content to load - try to find spending text
            try:
                await page.wait_for_selector('text=Spending so far', timeout=10000)
                print("‚úÖ Found 'Spending so far' text")
            except:
                print("‚ö†Ô∏è 'Spending so far' text not found, waiting longer...")
                await page.wait_for_timeout(5000)
            
            # Scroll down to trigger lazy loading
            await page.evaluate('window.scrollTo(0, document.body.scrollHeight / 2)')
            await page.wait_for_timeout(2000)
            
            # Take screenshot for debugging
            try:
                await page.screenshot(path='/tmp/tiktok_ads_page.png', full_page=True)
                print("üì∏ Screenshot saved to /tmp/tiktok_ads_page.png")
            except:
                pass
            
            # Get page content
            content = await page.content()
            
            print(f"üìù Page content length: {len(content)} chars")
            
            # Parse spending data - multiple patterns
            # HTML structure: "Spending so far..." <span>129,265,101</span> "VND"
            spending_patterns = [
                # Pattern cho s·ªë trong <span> tag sau "Spending so far"
                r'Spending\s+so\s+far[^<]*<span[^>]*>([\d,]+)</span>',
                # Pattern cho s·ªë sau "current billing cycle"
                r'current\s+billing\s+cycle[^<]*<span[^>]*>([\d,]+)</span>',
                # Pattern ƒë∆°n gi·∫£n - s·ªë trong span
                r'billing\s+cycle[^<]*<span[^>]*>([\d,]+)</span>',
            ]
            
            found_spending = False
            for pattern in spending_patterns:
                match = re.search(pattern, content, re.IGNORECASE)
                if match:
                    spending_str = match.group(1).replace(',', '').replace('.', '')
                    print(f"üîé Pattern matched: {pattern[:40]}... ‚Üí raw: {match.group(1)} ‚Üí clean: {spending_str}")
                    try:
                        spending = float(spending_str)
                        # Sanity check: s·ªë ph·∫£i > 1 tri·ªáu (1,000,000)
                        if spending > 1000000:
                            result["spending"] = spending
                            result["success"] = True
                            found_spending = True
                            print(f"‚úÖ Found spending: {result['spending']:,.0f} VND")
                            break
                        else:
                            print(f"‚ö†Ô∏è Spending too small: {spending}")
                    except ValueError as e:
                        print(f"‚ö†Ô∏è ValueError: {e}")
                        continue
            
            # Fallback: t√¨m spending v√† credit limit ri√™ng bi·ªát
            if not found_spending:
                print("‚ö†Ô∏è Could not find spending with patterns, trying smart fallback...")
                
                # 1. T√¨m Spending: s·ªë trong <span> sau "Spending so far"
                spending_match = re.search(
                    r'Spending\s+so\s+far[^<]*<span[^>]*>([\d,]+)</span>',
                    content, re.IGNORECASE | re.DOTALL
                )
                if spending_match:
                    spending_str = spending_match.group(1).replace(',', '')
                    try:
                        result["spending"] = float(spending_str)
                        result["success"] = True
                        found_spending = True
                        print(f"‚úÖ Found spending in span: {result['spending']:,.0f}")
                    except:
                        pass
                
                # 2. T√¨m Credit Limit: s·ªë trong <span> sau "spending reaches"
                credit_match = re.search(
                    r'spending\s+reaches[^<]*<span[^>]*>([\d,]+)</span>',
                    content, re.IGNORECASE | re.DOTALL
                )
                if not credit_match:
                    # Try simpler pattern
                    credit_match = re.search(
                        r'spending\s+reaches[^0-9]*([\d,]+)',
                        content, re.IGNORECASE
                    )
                if credit_match:
                    limit_str = credit_match.group(1).replace(',', '')
                    try:
                        result["credit_limit"] = float(limit_str)
                        print(f"‚úÖ Found credit limit: {result['credit_limit']:,.0f}")
                    except:
                        pass
                
                # 3. N·∫øu v·∫´n kh√¥ng t√¨m ƒë∆∞·ª£c spending, th·ª≠ t√¨m t·∫•t c·∫£ s·ªë trong <span> tags
                if not found_spending:
                    print("‚ö†Ô∏è Smart fallback failed, trying span number scan...")
                    
                    # T√¨m t·∫•t c·∫£ s·ªë trong <span> tags
                    span_numbers = re.findall(r'<span[^>]*>([\d,]+)</span>', content)
                    large_numbers = []
                    seen = set()
                    for num_str in span_numbers:
                        if num_str not in seen and ',' in num_str:  # Ch·ªâ l·∫•y s·ªë c√≥ comma (l·ªõn)
                            seen.add(num_str)
                            clean = num_str.replace(',', '')
                            try:
                                num = float(clean)
                                if num > 1000000:
                                    large_numbers.append((num_str, num))
                            except:
                                pass
                    
                    print(f"üìä Found {len(large_numbers)} numbers in span: {large_numbers[:5]}")
                    
                    # N·∫øu c√≥ √≠t nh·∫•t 2 s·ªë, s·ªë l·ªõn nh·∫•t = credit limit, s·ªë nh·ªè h∆°n = spending
                    if len(large_numbers) >= 2:
                        sorted_nums = sorted(large_numbers, key=lambda x: x[1], reverse=True)
                        result["credit_limit"] = sorted_nums[0][1]
                        result["spending"] = sorted_nums[1][1]
                        result["success"] = True
                        found_spending = True
                        print(f"‚úÖ Span scan: spending={sorted_nums[1][1]:,.0f}, limit={sorted_nums[0][1]:,.0f}")
                
                # Save content for debugging
                with open('/tmp/tiktok_ads_content.html', 'w', encoding='utf-8') as f:
                    f.write(content)
                print("üìù Saved page content to /tmp/tiktok_ads_content.html")
            
            # Parse credit limit (n·∫øu ch∆∞a c√≥ t·ª´ fallback)
            if result.get("credit_limit", 0) == CREDIT_LIMIT:
                limit_patterns = [
                    # Pattern cho s·ªë trong span sau "spending reaches"
                    r'spending\s+reaches[^<]*<span[^>]*>([\d,]+)</span>',
                    r'spending\s+reaches[^0-9]*([\d,]+)',
                    r'Or\s+when\s+ad\s+spending\s+reaches[^0-9]*([\d,]+)',
                ]
                
                for pattern in limit_patterns:
                    match = re.search(pattern, content, re.IGNORECASE | re.DOTALL)
                    if match:
                        limit_str = match.group(1).replace(',', '')
                        try:
                            limit = float(limit_str)
                            if limit > 100000000:  # > 100M VND
                                result["credit_limit"] = limit
                                print(f"‚úÖ Found credit limit: {result['credit_limit']:,.0f} VND")
                                break
                        except ValueError:
                            continue
            
            # Parse next billing date
            date_patterns = [
                r'Next\s+billing\s+date.*?([A-Z][a-z]{2}\s+\d{1,2},?\s+\d{4})',
                r'(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{1,2},?\s+\d{4}',
            ]
            
            for pattern in date_patterns:
                match = re.search(pattern, content, re.IGNORECASE)
                if match:
                    result["next_billing_date"] = match.group(1) if match.lastindex else match.group(0)
                    print(f"‚úÖ Found next billing: {result['next_billing_date']}")
                    break
            
            # Parse account name
            name_patterns = [
                r'Chenglovehair\d*',
                r'KALLE\s+FEUM',
            ]
            
            for pattern in name_patterns:
                match = re.search(pattern, content, re.IGNORECASE)
                if match:
                    result["account_name"] = match.group(0)
                    print(f"‚úÖ Found account name: {result['account_name']}")
                    break
            
            # Save cookies for next time
            cookies = await context.cookies()
            save_cookies(cookies)
            
            await browser.close()
            
            # Update cache
            if result["success"]:
                _cached_data["spending"] = result["spending"]
                _cached_data["credit_limit"] = result["credit_limit"]
                _cached_data["next_billing_date"] = result["next_billing_date"]
                _cached_data["account_name"] = result["account_name"]
                _cached_data["updated_at"] = datetime.now().isoformat()
                print(f"üíæ Updated cache: {_cached_data['spending']:,.0f} VND")
            
    except Exception as e:
        print(f"‚ùå Crawler error: {e}")
        import traceback
        traceback.print_exc()
        result["error"] = str(e)
        
        if browser:
            try:
                await browser.close()
            except:
                pass
    
    return result


async def get_spending_data(force_refresh: bool = False) -> Dict[str, Any]:
    """
    L·∫•y spending data (t·ª´ cache ho·∫∑c crawl m·ªõi)
    """
    # Check cache
    if not force_refresh and is_cache_valid():
        print("üì¶ Using cached data")
        return {
            "success": True,
            "spending": _cached_data["spending"],
            "credit_limit": _cached_data["credit_limit"],
            "next_billing_date": _cached_data["next_billing_date"],
            "account_name": _cached_data["account_name"],
            "updated_at": _cached_data["updated_at"],
            "from_cache": True
        }
    
    # Crawl new data
    print("üîÑ Cache expired or force refresh, crawling...")
    return await crawl_spending_data()


def format_spending_report(data: Dict[str, Any]) -> str:
    """Format b√°o c√°o chi ti√™u"""
    if not data.get("success"):
        error = data.get("error", "Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu")
        
        if data.get("login_required"):
            return (
                "‚ùå **C·∫ßn ƒëƒÉng nh·∫≠p TikTok Ads Manager**\n\n"
                "üí° **H∆∞·ªõng d·∫´n:**\n"
                "1. ƒêƒÉng nh·∫≠p TikTok Ads Manager tr√™n tr√¨nh duy·ªát\n"
                "2. Xu·∫•t cookies (d√πng extension nh∆∞ EditThisCookie)\n"
                "3. L∆∞u cookies v√†o `/tmp/tiktok_ads_cookies.json`\n"
                "4. Deploy l·∫°i Railway\n\n"
                f"üìù Chi ti·∫øt l·ªói: {error}"
            )
        
        return f"‚ùå {error}\n\nüí° Ki·ªÉm tra logs ƒë·ªÉ debug"
    
    spending = data["spending"]
    credit_limit = data["credit_limit"]
    percentage = (spending / credit_limit * 100) if credit_limit > 0 else 0
    
    lines = [
        "üí∞ **B√ÅO C√ÅO T√ÄI KHO·∫¢N TIKTOK ADS**",
        f"üìÖ C·∫≠p nh·∫≠t: {datetime.now().strftime('%H:%M %d/%m/%Y')}",
        "",
    ]
    
    if data.get("account_name"):
        lines.append(f"‚úÖ **{data['account_name']}**")
    else:
        lines.append(f"‚úÖ **Chenglovehair0422**")
    
    lines.append(f"üÜî ID: `{PRIMARY_ADVERTISER_ID}`")
    lines.append("")
    lines.append(f"üí≥ **D∆∞ n·ª£ hi·ªán t·∫°i: {spending:,.0f} / {credit_limit:,.0f} VND**")
    lines.append(f"üìä T·ª∑ l·ªá s·ª≠ d·ª•ng: **{percentage:.1f}%**")
    
    if data.get("next_billing_date"):
        lines.append(f"üìÜ Thanh to√°n ti·∫øp theo: {data['next_billing_date']}")
    
    lines.append("")
    
    # Warning
    if percentage >= WARNING_THRESHOLD:
        lines.append("üö®" * 5)
        lines.append(f"‚ö†Ô∏è **C·∫¢NH B√ÅO: D∆∞ n·ª£ ƒë√£ ƒë·∫°t {percentage:.1f}% h·∫°n m·ª©c!**")
        lines.append(f"üí° H·∫°n m·ª©c c√≤n l·∫°i: {credit_limit - spending:,.0f} VND")
        lines.append("üö®" * 5)
    elif percentage >= 70:
        lines.append(f"‚ö†Ô∏è L∆∞u √Ω: ƒê√£ s·ª≠ d·ª•ng {percentage:.1f}% h·∫°n m·ª©c")
    else:
        lines.append("‚úÖ M·ª©c s·ª≠ d·ª•ng an to√†n")
    
    # Cache info
    if data.get("from_cache"):
        lines.append("")
        lines.append("üì¶ D·ªØ li·ªáu t·ª´ cache")
    
    if data.get("updated_at"):
        try:
            dt = datetime.fromisoformat(data["updated_at"])
            lines.append(f"üïê C·∫≠p nh·∫≠t l√∫c: {dt.strftime('%H:%M %d/%m')}")
        except:
            pass
    
    return "\n".join(lines)


def check_warning_threshold() -> Optional[str]:
    """Ki·ªÉm tra c·∫£nh b√°o"""
    if not _cached_data["spending"]:
        return None
    
    spending = _cached_data["spending"]
    credit_limit = _cached_data["credit_limit"]
    percentage = (spending / credit_limit * 100) if credit_limit > 0 else 0
    
    if percentage >= WARNING_THRESHOLD:
        return (
            "üö® **C·∫¢NH B√ÅO TIKTOK ADS** üö®\n\n"
            f"üí≥ D∆∞ n·ª£: **{spending:,.0f} / {credit_limit:,.0f} VND**\n"
            f"üìä ƒê√£ s·ª≠ d·ª•ng: **{percentage:.1f}%** h·∫°n m·ª©c\n"
            f"üí° C√≤n l·∫°i: {credit_limit - spending:,.0f} VND\n\n"
            "‚ö†Ô∏è Vui l√≤ng ki·ªÉm tra v√† thanh to√°n s·ªõm!"
        )
    
    return None


def is_tiktok_ads_query(text: str) -> bool:
    """Ki·ªÉm tra query TikTok Ads"""
    keywords = [
        "s·ªë d∆∞ tiktok", "so du tiktok", 
        "tiktok ads", "tkqc", 
        "qu·∫£ng c√°o tiktok", "quang cao tiktok",
        "ti·ªÅn qu·∫£ng c√°o", "tien quang cao",
        "chi ti√™u tiktok", "chi tieu tiktok",
        "d∆∞ n·ª£ tiktok", "du no tiktok",
        "d∆∞ n·ª£ ads", "du no ads",
        "balance tiktok", "spending tiktok"
    ]
    text_lower = text.lower()
    return any(kw in text_lower for kw in keywords)
